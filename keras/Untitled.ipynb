{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Convolution2D, MaxPooling2D, Flatten\n",
    "from PIL import Image\n",
    "import glob\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imgs = 10\n",
    "\n",
    "img_size = 32\n",
    "num_objects = 2\n",
    "\n",
    "imgs = np.zeros((num_imgs, img_size, img_size, 4), dtype=np.uint8)  # format: BGRA\n",
    "shapes = np.zeros((num_imgs, num_objects), dtype=int)\n",
    "num_shapes = 13\n",
    "num_text = 36\n",
    "shape_labels = ['circle', 'semicircle', 'quartercircle', 'triangle', 'square', 'rectangle', 'trapezoid', 'pentagon', 'hexagon', 'heptagon', 'octagon', 'star', 'cross']\n",
    "text_labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
    "               '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "colors = np.zeros((num_imgs, num_objects), dtype=int)\n",
    "num_colors = 3\n",
    "color_labels = ['r', 'g', 'b']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307, 40, 40, 3)\n",
      "(307, 13)\n",
      "(77, 40, 40, 3)\n",
      "(77, 13)\n",
      "(384, 40, 40, 3)\n",
      "(384, 13)\n"
     ]
    }
   ],
   "source": [
    "def getImgs(imgs_path):\n",
    "    imgs = []\n",
    "    for filename in glob.glob(imgs_path):\n",
    "        img = cv2.imread(filename)\n",
    "        imgs.append(img)\n",
    "    return np.array(imgs)\n",
    "\n",
    "def getLabels(labels_path):\n",
    "    labels = []\n",
    "    for filename in glob.glob(labels_path):\n",
    "        with open(filename) as file:\n",
    "            label = json.load(file)\n",
    "            #labels.append([label['shape_type'], label['character']])\n",
    "            labels.append([shape_labels.index(label['shape_type'])])\n",
    "    return np.array(labels)\n",
    "      \n",
    "imgs_path = '../cnn_training_data/*.jpg';\n",
    "labels_path = '../cnn_training_data/*.json';\n",
    "\n",
    "data = getImgs(imgs_path)\n",
    "label = keras.utils.to_categorical(getLabels(labels_path), num_classes=13)\n",
    "\n",
    "train_d = data[:(int) (data.shape[0]*0.8),...] \n",
    "train_l = label[:(int) (data.shape[0]*0.8),...] \n",
    "test_d = data[(int) (data.shape[0]*0.8):,...] \n",
    "test_l = label[(int) (data.shape[0]*0.8):,...] \n",
    "\n",
    "print(train_d.shape)\n",
    "print(train_l.shape)\n",
    "print(test_d.shape)\n",
    "print(test_l.shape)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(train_labels.shape)\n",
    "\n",
    "\n",
    "data_shape = data[0].shape\n",
    "label_shape = label.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kratos/.local/lib/python2.7/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (6, 6), activation=\"relu\", data_format=\"channels_last\", input_shape=(40, 40, 3...)`\n",
      "  app.launch_new_instance()\n",
      "/home/kratos/.local/lib/python2.7/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", data_format=\"channels_last\")`\n",
      "/home/kratos/.local/lib/python2.7/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", data_format=\"channels_last\")`\n",
      "/home/kratos/.local/lib/python2.7/site-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", data_format=\"channels_last\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 4s - loss: 7.4673 - acc: 0.0749\n",
      "Epoch 2/100\n",
      " - 2s - loss: 8.4059 - acc: 0.0945\n",
      "Epoch 3/100\n",
      " - 2s - loss: 7.4330 - acc: 0.0619\n",
      "Epoch 4/100\n",
      " - 3s - loss: 7.9761 - acc: 0.0717\n",
      "Epoch 5/100\n",
      " - 3s - loss: 8.2695 - acc: 0.0684\n",
      "Epoch 6/100\n",
      " - 3s - loss: 8.3649 - acc: 0.0879\n",
      "Epoch 7/100\n",
      " - 3s - loss: 8.7416 - acc: 0.1107\n",
      "Epoch 8/100\n",
      " - 3s - loss: 7.9969 - acc: 0.0847\n",
      "Epoch 9/100\n",
      " - 3s - loss: 8.3007 - acc: 0.0879\n",
      "Epoch 10/100\n",
      " - 3s - loss: 7.3854 - acc: 0.0912\n",
      "Epoch 11/100\n",
      " - 4s - loss: 8.0791 - acc: 0.0684\n",
      "Epoch 12/100\n",
      " - 3s - loss: 7.7741 - acc: 0.0717\n",
      "Epoch 13/100\n",
      " - 4s - loss: 8.0834 - acc: 0.0782\n",
      "Epoch 14/100\n",
      " - 5s - loss: 7.8269 - acc: 0.0814\n",
      "Epoch 15/100\n",
      " - 4s - loss: 8.2505 - acc: 0.0977\n",
      "Epoch 16/100\n",
      " - 3s - loss: 8.0140 - acc: 0.0684\n",
      "Epoch 17/100\n",
      " - 3s - loss: 7.3711 - acc: 0.0847\n",
      "Epoch 18/100\n",
      " - 3s - loss: 8.6444 - acc: 0.0749\n",
      "Epoch 19/100\n",
      " - 2s - loss: 8.0770 - acc: 0.0717\n",
      "Epoch 20/100\n",
      " - 3s - loss: 8.8495 - acc: 0.0684\n",
      "Epoch 21/100\n",
      " - 2s - loss: 8.2704 - acc: 0.0521\n",
      "Epoch 22/100\n",
      " - 2s - loss: 8.9549 - acc: 0.0651\n",
      "Epoch 23/100\n",
      " - 2s - loss: 8.0280 - acc: 0.0521\n",
      "Epoch 24/100\n",
      " - 2s - loss: 8.5966 - acc: 0.0814\n",
      "Epoch 25/100\n",
      " - 2s - loss: 8.3633 - acc: 0.0847\n",
      "Epoch 26/100\n",
      " - 3s - loss: 7.5246 - acc: 0.1075\n",
      "Epoch 27/100\n",
      " - 3s - loss: 6.7398 - acc: 0.0977\n",
      "Epoch 28/100\n",
      " - 3s - loss: 7.7818 - acc: 0.1010\n",
      "Epoch 29/100\n",
      " - 2s - loss: 8.0508 - acc: 0.0782\n",
      "Epoch 30/100\n",
      " - 3s - loss: 7.1577 - acc: 0.0912\n",
      "Epoch 31/100\n",
      " - 2s - loss: 8.4765 - acc: 0.0879\n",
      "Epoch 32/100\n",
      " - 2s - loss: 7.6221 - acc: 0.0814\n",
      "Epoch 33/100\n",
      " - 2s - loss: 8.1088 - acc: 0.0977\n",
      "Epoch 34/100\n",
      " - 3s - loss: 8.1061 - acc: 0.0879\n",
      "Epoch 35/100\n",
      " - 2s - loss: 7.2209 - acc: 0.0782\n",
      "Epoch 36/100\n",
      " - 2s - loss: 8.3013 - acc: 0.0912\n",
      "Epoch 37/100\n",
      " - 2s - loss: 7.7350 - acc: 0.0879\n",
      "Epoch 38/100\n",
      " - 2s - loss: 9.1395 - acc: 0.0814\n",
      "Epoch 39/100\n",
      " - 3s - loss: 8.6759 - acc: 0.0912\n",
      "Epoch 40/100\n",
      " - 2s - loss: 8.0867 - acc: 0.0847\n",
      "Epoch 41/100\n",
      " - 2s - loss: 8.8858 - acc: 0.0684\n",
      "Epoch 42/100\n",
      " - 3s - loss: 8.5629 - acc: 0.0749\n",
      "Epoch 43/100\n",
      " - 2s - loss: 8.5053 - acc: 0.0879\n",
      "Epoch 44/100\n",
      " - 2s - loss: 7.3543 - acc: 0.1010\n",
      "Epoch 45/100\n",
      " - 3s - loss: 8.6662 - acc: 0.0684\n",
      "Epoch 46/100\n",
      " - 2s - loss: 7.9828 - acc: 0.0651\n",
      "Epoch 47/100\n",
      " - 3s - loss: 7.8753 - acc: 0.0684\n",
      "Epoch 48/100\n",
      " - 3s - loss: 7.5090 - acc: 0.1107\n",
      "Epoch 49/100\n",
      " - 3s - loss: 7.3568 - acc: 0.0619\n",
      "Epoch 50/100\n",
      " - 3s - loss: 8.0358 - acc: 0.0651\n",
      "Epoch 51/100\n",
      " - 3s - loss: 8.5055 - acc: 0.0717\n",
      "Epoch 52/100\n",
      " - 3s - loss: 8.4013 - acc: 0.0879\n",
      "Epoch 53/100\n",
      " - 2s - loss: 8.0995 - acc: 0.0554\n",
      "Epoch 54/100\n",
      " - 2s - loss: 8.0328 - acc: 0.0782\n",
      "Epoch 55/100\n",
      " - 2s - loss: 8.1904 - acc: 0.0651\n",
      "Epoch 56/100\n",
      " - 2s - loss: 7.6658 - acc: 0.0782\n",
      "Epoch 57/100\n",
      " - 2s - loss: 8.1917 - acc: 0.0945\n",
      "Epoch 58/100\n",
      " - 2s - loss: 7.7181 - acc: 0.0814\n",
      "Epoch 59/100\n",
      " - 3s - loss: 7.9278 - acc: 0.0945\n",
      "Epoch 60/100\n",
      " - 2s - loss: 8.3482 - acc: 0.0912\n",
      "Epoch 61/100\n",
      " - 2s - loss: 7.1967 - acc: 0.0945\n",
      "Epoch 62/100\n",
      " - 2s - loss: 8.4564 - acc: 0.0619\n",
      "Epoch 63/100\n",
      " - 2s - loss: 7.7201 - acc: 0.0619\n",
      "Epoch 64/100\n",
      " - 2s - loss: 8.1903 - acc: 0.0684\n",
      "Epoch 65/100\n",
      " - 2s - loss: 8.0854 - acc: 0.0651\n",
      "Epoch 66/100\n",
      " - 2s - loss: 8.2953 - acc: 0.0847\n",
      "Epoch 67/100\n",
      " - 2s - loss: 8.6103 - acc: 0.0717\n",
      "Epoch 68/100\n",
      " - 2s - loss: 7.7703 - acc: 0.0749\n",
      "Epoch 69/100\n",
      " - 2s - loss: 7.9278 - acc: 0.0977\n",
      "Epoch 70/100\n",
      " - 3s - loss: 8.0328 - acc: 0.0717\n",
      "Epoch 71/100\n",
      " - 2s - loss: 8.1378 - acc: 0.0879\n",
      "Epoch 72/100\n",
      " - 2s - loss: 7.9278 - acc: 0.0945\n",
      "Epoch 73/100\n",
      " - 2s - loss: 8.1378 - acc: 0.0651\n",
      "Epoch 74/100\n",
      " - 2s - loss: 7.7207 - acc: 0.0814\n",
      "Epoch 75/100\n",
      " - 2s - loss: 8.1378 - acc: 0.0619\n",
      "Epoch 76/100\n",
      " - 2s - loss: 8.2974 - acc: 0.0456\n",
      "Epoch 77/100\n",
      " - 2s - loss: 8.7693 - acc: 0.0651\n",
      "Epoch 78/100\n",
      " - 2s - loss: 7.5078 - acc: 0.1010\n",
      "Epoch 79/100\n",
      " - 2s - loss: 7.7178 - acc: 0.0782\n",
      "Epoch 80/100\n",
      " - 3s - loss: 7.5604 - acc: 0.0684\n",
      "Epoch 81/100\n",
      " - 2s - loss: 7.8262 - acc: 0.0847\n",
      "Epoch 82/100\n",
      " - 2s - loss: 7.0353 - acc: 0.0912\n",
      "Epoch 83/100\n",
      " - 2s - loss: 8.4003 - acc: 0.0945\n",
      "Epoch 84/100\n",
      " - 2s - loss: 8.0853 - acc: 0.0879\n",
      "Epoch 85/100\n",
      " - 2s - loss: 8.0328 - acc: 0.0977\n",
      "Epoch 86/100\n",
      " - 3s - loss: 8.3484 - acc: 0.0717\n",
      "Epoch 87/100\n",
      " - 4s - loss: 8.2431 - acc: 0.0814\n",
      "Epoch 88/100\n",
      " - 3s - loss: 7.7703 - acc: 0.0945\n",
      "Epoch 89/100\n",
      " - 3s - loss: 7.6653 - acc: 0.0847\n",
      "Epoch 90/100\n",
      " - 3s - loss: 8.7678 - acc: 0.0912\n",
      "Epoch 91/100\n",
      " - 3s - loss: 8.0332 - acc: 0.0912\n",
      "Epoch 92/100\n",
      " - 3s - loss: 7.6653 - acc: 0.0651\n",
      "Epoch 93/100\n",
      " - 3s - loss: 8.4528 - acc: 0.0684\n",
      "Epoch 94/100\n",
      " - 4s - loss: 9.0303 - acc: 0.0847\n",
      "Epoch 95/100\n",
      " - 5s - loss: 8.1378 - acc: 0.0912\n",
      "Epoch 96/100\n",
      " - 5s - loss: 7.7178 - acc: 0.0879\n",
      "Epoch 97/100\n",
      " - 4s - loss: 7.5078 - acc: 0.0749\n",
      "Epoch 98/100\n",
      " - 5s - loss: 8.3478 - acc: 0.0717\n",
      "Epoch 99/100\n",
      " - 3s - loss: 8.0853 - acc: 0.1042\n",
      "Epoch 100/100\n",
      " - 3s - loss: 7.8228 - acc: 0.0619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc2e4161b50>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Make one run with very deep network (~10 layers).\n",
    "filter_size = 3\n",
    "pool_size = 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Make one run with very deep network (~10 layers).\n",
    "filter_size = 3\n",
    "pool_size = 2\n",
    "\n",
    "# TODO: Maybe remove pooling bc it takes away the spatial information.\n",
    "\n",
    "model = Sequential([\n",
    "        Convolution2D(32, 6, 6, input_shape=data_shape, dim_ordering='tf', activation='relu'), \n",
    "        MaxPooling2D(pool_size=(pool_size, pool_size)), \n",
    "        Convolution2D(64, filter_size, filter_size, dim_ordering='tf', activation='relu'), \n",
    "        MaxPooling2D(pool_size=(pool_size, pool_size)), \n",
    "        Convolution2D(128, filter_size, filter_size, dim_ordering='tf', activation='relu'), \n",
    "# #         MaxPooling2D(pool_size=(pool_size, pool_size)), \n",
    "        Convolution2D(128, filter_size, filter_size, dim_ordering='tf', activation='relu'), \n",
    "# #         MaxPooling2D(pool_size=(pool_size, pool_size)), \n",
    "        Flatten(), \n",
    "        Dropout(0.4), \n",
    "        Dense(256, activation='relu'), \n",
    "        Dropout(0.4), \n",
    "        Dense(label_shape)\n",
    "    ])\n",
    "\n",
    "#model.compile('adadelta', 'mse')\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#model.save_weights('bottleneck_fc_model.h5')\n",
    "model.fit(train_d, train_l, epochs=100, batch_size=128, verbose=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "307/307 [==============================] - 10s 31ms/step - loss: 14.6165 - acc: 0.0879\n",
      "Epoch 2/100\n",
      "307/307 [==============================] - 8s 25ms/step - loss: 14.8580 - acc: 0.0782\n",
      "Epoch 3/100\n",
      "307/307 [==============================] - 10s 34ms/step - loss: 15.1206 - acc: 0.0619\n",
      "Epoch 4/100\n",
      "307/307 [==============================] - 11s 35ms/step - loss: 14.7530 - acc: 0.0847\n",
      "Epoch 5/100\n",
      "307/307 [==============================] - 11s 37ms/step - loss: 14.8055 - acc: 0.0814\n",
      "Epoch 6/100\n",
      "307/307 [==============================] - 10s 31ms/step - loss: 14.7530 - acc: 0.0847\n",
      "Epoch 7/100\n",
      "307/307 [==============================] - 10s 34ms/step - loss: 14.7530 - acc: 0.0847\n",
      "Epoch 8/100\n",
      "307/307 [==============================] - 9s 30ms/step - loss: 14.8580 - acc: 0.0782\n",
      "Epoch 9/100\n",
      "307/307 [==============================] - 9s 28ms/step - loss: 14.9106 - acc: 0.0749\n",
      "Epoch 10/100\n",
      "307/307 [==============================] - 8s 26ms/step - loss: 15.0156 - acc: 0.0684\n",
      "Epoch 11/100\n",
      "307/307 [==============================] - 8s 25ms/step - loss: 14.8055 - acc: 0.0814\n",
      "Epoch 12/100\n",
      "307/307 [==============================] - 8s 25ms/step - loss: 14.9106 - acc: 0.0749\n",
      "Epoch 13/100\n",
      "307/307 [==============================] - 8s 25ms/step - loss: 14.7530 - acc: 0.0847\n",
      "Epoch 14/100\n",
      "307/307 [==============================] - 8s 25ms/step - loss: 15.1731 - acc: 0.0586\n",
      "Epoch 15/100\n",
      "307/307 [==============================] - 8s 25ms/step - loss: 14.6480 - acc: 0.0912\n",
      "Epoch 16/100\n",
      "307/307 [==============================] - 8s 25ms/step - loss: 14.9106 - acc: 0.0749\n",
      "Epoch 17/100\n",
      "307/307 [==============================] - 8s 26ms/step - loss: 15.0156 - acc: 0.0684\n",
      "Epoch 18/100\n",
      "307/307 [==============================] - 8s 27ms/step - loss: 14.8055 - acc: 0.0814\n",
      "Epoch 19/100\n",
      "307/307 [==============================] - 8s 25ms/step - loss: 15.3306 - acc: 0.0489\n",
      "Epoch 20/100\n",
      "307/307 [==============================] - 8s 25ms/step - loss: 15.1206 - acc: 0.0619\n",
      "Epoch 21/100\n",
      "307/307 [==============================] - 8s 25ms/step - loss: 14.9631 - acc: 0.0717\n",
      "Epoch 22/100\n",
      "307/307 [==============================] - 10s 32ms/step - loss: 15.1206 - acc: 0.0619\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-4d0ae618d748>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msgd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training_arrays.pyc\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kratos/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# input: 100x100 images with 3 channels -> (100, 100, 3) tensors.\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model.add(Convolution2D(32, (5, 5), activation='relu', input_shape=data_shape))\n",
    "model.add(Convolution2D(32, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(13, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_d, train_l, batch_size=32, epochs=100)\n",
    "score = model.evaluate(test_d, test_l, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mnist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-228eacda40b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#train_x = train_x.astype('float32') / 255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#test_x = test_x.astype('float32') / 255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mnist' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "model.save_weights('first_try.h5')  # always save your weights after training or during training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6]\n",
      " [6]\n",
      " [6]\n",
      " [4]\n",
      " [9]\n",
      " [6]\n",
      " [4]\n",
      " [7]\n",
      " [5]\n",
      " [4]]\n",
      "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=4, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "estimator = KerasClassifier(build_fn=model, epochs=200, batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc308bb35d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJztnXmMZNd13r/zXr1ae5vpmR7OwmW4iNSQJofmkKIsJlKoyGCEAJIBQ7GCGAwggA4QATZiBGb8jxfEgAzYVv5I4ICGGTGAY0mQ7Ugx5CQMw8QxQlOkyBHFRRTXEWc4K2d6qa71vXfyRxWZqT7f5RS7Z6rZ884PGEz37Vvv3becelXf/e45oqpwHKd4RJs9AMdxNgcPfscpKB78jlNQPPgdp6B48DtOQfHgd5yC4sHvOAXFg99xCsqGgl9E7hORl0XkVRF58GINynGcS4+s1+EnIjGAHwP4DICjAJ4C8EVVfTH0mlJS1kq1vmY7oR3YpizLaFd2BFEUeF8jx6t0C3zLWZ6Ova88z02baOiA2e55X7a/0DEIOcGlOKF905QdG3l9ib++T14fRzHtq2rPTej6spskdNuy/eVqtyvCN5CrPQZ6Mw5GYVqyzB4XALA4k8B2Q+eXsXYbvW4Hab8/1k1WGnsvlrsAvKqqrwOAiHwdwOcABIO/Uq3jwKG/M9IWx4EbnLQvryzRvikJsnq9TnoCadYzbQp2wQGN+qZtaeUd09aoVenrW62WaYuVX9g8tccrGe9bI8eWw44VAOJSxbQtbNtN+546eca01afLpm1++w76+tOn7fVpNBq0b5p1TdvS8iLtK7G9TdMeD96pxqxpa3dXTFupbPcPAK3eOdtXAg8S8gaytNikXXs9e9/FYs8tACzs3GV3FRhDJKPn5pXDz9J+9LVj97TsBfDWeb8fHbY5jrMF2MiTfyxE5AEADwBAuVK71LtzHGdMNvLkPwbgyvN+3zdsG0FVH1LVQ6p6qJTwjzmO40yejTz5nwJwg4jsxyDofwHAP36/F0gkKJdHd8lEJgBoNldNW6Viv78CQAlW0Al9B+6n9rvXSpN/14xK9jtdr2e3m4RErdx+j48CfaOYtQf6RvayJQERr1S2ekQv5aJUuWzfnCOxY+i0+fdlJYJdr9Ohfdn38LjEn0VKNJ1KjR9vlbQvd+w1b3ft/QVwIbLdbfO+qT3efp/fzzG5Zppz3eLcOas7RBI43uro9WUic4h1B7+qpiLyZQD/DYO79GFVfWG923McZ7Js6Du/qn4XwHcv0lgcx5kg7vBznILiwe84BcWD33EKyiWf5z+fLEtxbmnUIRdTlRuoEk8As9YCwGpz2bSVytw5uLhkHXrdHlekx7Y+E3cewG245TI/Xqhtr1S4O252at60hc5js21dhllA7S+V7WxKv28V7STmr09Kdgyrq9yVWa3ZmYV+FpgZIO29Lr8X2n2r4kvFXp9ywm/95ordbqdtZwsAYHZqxrTVq3y7KTmPMXEuAkCjPm3ayCTEYGyB2ZRx8Ce/4xQUD37HKSge/I5TUDz4HaegTFTwExFUqqM2xTTlNtxOzwo3WcZFnjS3dtN+h/dlKyPn5uZo317Xjq0UEwtswLLLlmw2qnypcZfsa6phhR8gNF4uOna7VqxiNl4AWO1YcbBHzm2vafsBQELW/s/O8sVcrZa9vu0uXw6bEav2EhF5ASBJrBU3qVhrbKr8GEpEON2x3S6xBYBqYq3T/T6/n4XkFKjXuKDLcjAQpzgAoBSPirTstSH8ye84BcWD33EKige/4xQUD37HKSge/I5TUCaq9isU/TUW3Wabq7ZlYhVdXuFJN8olexghu6sSMbY+w1XXEulcq1m1PgJPMhKR09uYtgkmAaDZtEp3ucoTg7IMsyzhBQB0Ona7eRSaNbHHG5dtX4m57TkhUynNLrf39vpWbW/3bIIPAKiQ81Ap8+dWuWTV7pgk2iyDz3hkPXseV1Z44o9emWTkDajtbIalUuYzP+xeSHv8miXJ2pkMV/sdx7kAHvyOU1A8+B2noHjwO05B2ZDgJyJvAlgBkAFIVfXQ+/VP0z5Onzkx0jY1zcU2trY7kKAWJSIOdlrcZskss/0eLxO11joJAJVkynbMQ6XB7LhKERcHG0T7YVWLAGBl1QpQROcCAGRi7bkd8Gy0te32dijXrah16tQp+vrVlj0PTEADeDWjqSlybgE0SfbcXiDr887t2+wYiHW63+LnIMrIOahw4bXRsOv5Q9lzWcWelWVuZ2637dgqxEoM2Io9H0Twuxhq/99TVVvnyXGcDzX+sd9xCspGg18B/HcR+f6wLJdBRB4QkadF5OmcFDlwHGdz2OjH/ntU9ZiILAB4VER+pKp/fX4HVX0IwEMAkNSq66sH7jjORWdDT35VPTb8/xSAv8CgbLfjOFuAdT/5RaQBIFLVleHPPwvgt9//Rbb+XavNFc+YqJahemWa2fcwCb2vEWU+Clg9SxFJ3EEU/G7Aeskcxu0Ot4pmJFNwt8lr4rFsw3keyECcWMvs1HauSN9051Wmbd/+7abtxed5Ntsf/t+fmLY0D1ifqyTTbyCxS0QKvO6Y4Qk24pJNHtJZsV83K8JnFiSx90cpkICF1UyME24rr1ftrFaLqPoAEBP7dbnK7/1oTQKVD5DLY0Mf+3cB+Iuhl7kE4D+p6n/dwPYcx5kgGynU+TqA2y7iWBzHmSA+1ec4BcWD33EKymTX8+eKbndUxAplkq1WiSCjXM3orBIrsHChKYmtTTJUvioya6UBVSIuBlSWSt2OISdrywFAiC20GyhflcckI+8UFx3rxLJ78ycWaN9rD9hcA1HFCpS3z+ylr9eePbYf/q0VAQfY67CyxAVOVgYsS/h5XOnac1Yl6+ZrQfHYioN54BnJLLvh+9kebyjnRGPKipaNBrfBt9pcQB4Hf/I7TkHx4HecguLB7zgFxYPfcQqKB7/jFJSJqv1RFKFRH02mUQtYJxsVpvZzdXSuQZJIBBT8StmqvBlReAFgesaq3ysr1i5bIpZQACiTGnHLLZ7NNs2stbU+w4+3S+rnLVzFx3Dr3ftN254b+UxIVjpn2iqk63SD19+75aCdReivcAX/he+dNm018HsBOZl1Sfm5SSKrqiuZjUkDGYjZhFIaqL8XReM/O1nG5XKFh1+FxESLJDQBgN6a+0aJTTyEP/kdp6B48DtOQfHgd5yC4sHvOAVlooJfkiS4YtfukbYeyawK8Cy3zKYJABnJvtvL+Zpzlt1027xdsw4AkVhRqd21AlYpsIa7vWhFrVS5cNOYsaJWGvFSZvM7bdudn7yG9p3dTcTMCt+uRNYaW2KKX4+LeLv2WSHwto9dTft2l+11ePkHZ2nf7TNXmDbNeDbbLCWCV2TbUnBBuFazx6AasB0nNnzSQE6CTiDnA2P5jC1LJ4H0zGtzO+TKj4vhT37HKSge/I5TUDz4HaegePA7TkG5oOAnIg8D+IcATqnqLcO27QC+AeAaAG8C+IKqWnvYWlQg2ag4ViWiyaAvce0FnHiNGVuCS0g5KAA4e8aWmuoQES8Ec1Cx8koAQHJJQomoBgAtWLHrquttOSgAuOWQXU+/7UouNEnZ7k/iQP2E3AqX1NyWc/GqVCPOw6u5MHfHp66x4wo8i5aPWbGr3+Yia4ncTp0uuRcC+QBytRsoVfi+2P1YrvL1/CzpKgKi40rLCrKhnBFr1/5/kASe4zz5vwbgvjVtDwJ4TFVvAPDY8HfHcbYQFwz+YRGOtY+lzwF4ZPjzIwA+f5HH5TjOJWa98/y7VPX48OcTGKTxpgzLeD0AAGWSyshxnM1hw4KfDr4EB5cSqepDqnpIVQ+VSPEFx3E2h/UG/0kR2Q0Aw/95wXbHcT60rPdj/3cA3A/gK8P/vz3Oi1QV/e6owpmQDLmh9m6HW3arVStJh5Za16dtFtRmk5cMY+u1E6LmlhMusfZhVdu8xK2119xocwfccif/NrVjn91fXONZXBWkVFUpZJMmqnbXtsUlfnL7LNtwmX8o3HO9vQ4RrqV9n/ofJ03b2WN8Nicmtl+WUTcXPjvST+09Vinzr6tNUmouCeQZWO3YGaF6nedFqNft9Ukzfu+HZsDG4YJPfhH5UwBPALhRRI6KyJcwCPrPiMgrAP7+8HfHcbYQF3zyq+oXA3/69EUei+M4E8Qdfo5TUDz4HaegTHQ9fxyVMDM9KmzNzlqhCwDabWsVTftcLGMizZmzdi39oC9Zjx8oscQScEpsra2dnDubK9usqHT9AbIYH8CtH7OW3fm9/PJ0Urs/ibjoGBO7qgTczJW+FaDyvhWwQvkLQIRArXLBrxPbazlHREAAuGHV3iMv/i2/vmePkESo1XnT1k9DoqW9vv02FxcR23PeC6znX5toEwB6geSmzMpbKfGkq6vN0bFlma/ndxznAnjwO05B8eB3nILiwe84BcWD33EKykTVfoUiXVNGq9nkSipLkFENrApcJckPeilPOJHlVg3td7i9t0LE5yy2fStTPEHHgTv2mLaP3GaVZwCYmrfj6mY2iysAxEQNjlsBq2hm95ed5Mpxvmxvh/aivQ5ZzBXlqT02C3JpRyBr7ZRV6ztlrn5ffbNV+zttrqq3m2dMW+ucnR3RnN/67ZYdg3AHOjode++WWDYRAAmZIREJ9SUl5UiGasBa0C92Mg/HcS5DPPgdp6B48DtOQfHgd5yCMlHBDzmQ90btnim4cLOysmLaymU+3JSUKKpVuVW0uUrEQeVrpVu5FY9mdth93Xq3teYCwDU3zZm2pMEz/cYV+z4cymZb7VkBTBZ5ybHTh63QdO6JwPr0N+2xaZeIe1Uu4s3fYI+3cYD3nbub5BnYxst1acP2vfpmm7EZADotez/9+Bmba2bpJD+3q127r0aF5z/IxVqXK3V+bknSZ+R9fm66pIRdt8VF5UZj9D4XGf957k9+xykoHvyOU1A8+B2noHjwO05BGSeH38MickpEnj+v7TdF5JiIHB7+++ylHabjOBebcdT+rwH4twD+45r2r6rq732QnUkkqFRGraVZztV+puznyi2Ovb5V6+NALbakbhXWdo/baBs7rHL78U8fMG3ze3lyi/KUtYoyyzAAZGr7MoUYAHqrxMN5hNt7X/vfVunOf8JnBmbibaZt17ULpu2dJk+k8daPT9h9NZdo32uusNd9YRs/j3HJXt/tu/ite92ttr5hq2Nnjt45c9y0AYAk1vrc6XBVXmHHu0pmqQAgS+2sSTkO1bGw17cRmL2qr5mJYBmnQ6y3XJfjOFucjXzn/7KIPDf8WmAfGY7jfKhZb/D/IYDrABwEcBzA74c6isgDIvK0iDzd741fCttxnEvLuoJfVU+qaqaqOYA/AnDX+/R9r1ZfUuZLSR3HmTzrsveKyO7zqvT+HIDn36//u2R5hqXVUfkgIhlQAaCX2bXSHVLyCABist66nfLyVR1SVnD/ASsSAcDP/KwV93bssW9gpRpf356R+qVRQORRYlHOScZXACjlVohceYvbSntn7fndcTPf7k9/esq01fbbc74SSGZ77Fl7O73xNs9sLFN2vBrICqwR+cQYcUv2diK+3nz3FabtzEku8h550QqUZbG2ZQBAz57bUsRDKkpse49YiQGYknYAoIHnZjke/UNExMIQFwz+YbmuTwHYISJHAfwGgE+JyEEMqvO+CeCXxt6j4zgfCtZbruuPL8FYHMeZIO7wc5yC4sHvOAXFg99xCspEk3mIKKJkVMnsBeb+2ySjbh4oMsessahytf+jt9haefd8+qdo39oOq4pX6kSVB1f7Nbdqf5ZxhZdlFQ7V39OcvGe3+CyC9G37wvwO2jduWBvrCXnZtEUL3O669x673W3t/bQvdpJajDG/ZmzWBAGrd1yxfXfsstbnuz55A3192n3JtJ16g48rV1LbsMOvmai9Zmmf+7enGjZZS73OE4rUa6MzNFEUqKNI8Ce/4xQUD37HKSge/I5TUDz4HaegTFTwy1XRy0ezkKbCraZStmJIt8fLaiU1K8h89PbdtO+hv2sFqEZAwCpVrQiX5tZWquDikxIRj63rHmzDticlXieqXLLv2ZVp/j6uxIJ6+rmA0FSxHtId99rz1az8hL6+VbfZjrNZfrxpZM9ZngWuAxOxgllq7S0tkR3D/uu5pTvObzJtj/0XKwICwNmjdruRcmGuHNlsw9tmuSV7ZsaOLaTjnVtTiizL+b3I8Ce/4xQUD37HKSge/I5TUDz4HaegePA7TkGZbK0+5Mgwmhxiqc2TKrRWbVKFuQUued75yetN282H9tC+s7usgt7JeMKJSJlybJVykYClk9hzQ32Z61cD6XtF7HmYn+MZeRtVex6bp3ndt2eesDlZektW6b7rH11NXx/ttDM3acz3lROLcuh4U5LUJHQemSNaSvZ89fr8mu/Zb5X2j91rk7oAwBOPvmHaOmf4uBLY+65S4xmXl5t2Vmv7Nj47sW3baKKROB4/pP3J7zgFxYPfcQqKB7/jFJRxynVdKSKPi8iLIvKCiPzysH27iDwqIq8M//fc/Y6zhRhHHUgB/KqqPiMi0wC+LyKPAvinAB5T1a+IyIMAHgTwa++3IUWOPkYFoJ4u074L+63V9ODdfG34wZ/ZZ9pYqSyAi3slIggBQE7W4yeJFW4kYFHOiYAVh5Zbs+y9Kbe75iTr64lXeVGlvG2326txm3S0YNPy7rv1KtOWVvhBlFLyLCHr2AEgZici5tZUIedGhIuDvdyes0rVCmuhLLd9WKv4TbfbkmUA0Fy199jxH/Fzc/ZtOy4NZCDurtqSX6uBjMlry9+B5T4IME65ruOq+szw5xUALwHYC+BzAB4ZdnsEwOfH3qvjOJvOB/rOLyLXALgdwJMAdp2Xu/8EgF0XdWSO41xSxg5+EZkC8GcAfkV19LO6DiZo6eeN88t1Zf3xVxw5jnNpGSv4RSTBIPD/RFX/fNh8UkR2D/++GyClcDBarisOVGRxHGfyjFOxRzAo0vGSqv7BeX/6DoD7AXxl+P+3L7StXFOs9kfXfO+91iYrBIBD91jX3nU3cxdbMmVFmrzEky6WY/t+FzCLodcha85Z8szAev6MiE9U6AJ3rGVpwPHWtwLYypJ18gFA2rOi0l0fv5323XuHnbA5PfuqaStlXEzNz1k3Xzfi42o27Nr/eJoLnGzpfh4QtiLY88sKxNbrfC29CBHhUivAAcDNd1gXaZUIhgDQXH7btHWb/DxOzTTsuAI6XsgVOQ7jqP2fAPCLAH4oIoeHbb+OQdB/U0S+BOAIgC+sexSO40ycccp1/Q0QrP736Ys7HMdxJoU7/BynoHjwO05B8eB3nIIy0fX8cSKY3z26yzs/YVV9ALjmo3b9cqnBbalI2qZJYm657RMFPSLr4wEgqTArr1XaNeenUYhMnacB+SS3Y4g/SOmlKlfKKzW7v7M/4eexXrGZZ2ev3Gva3vr+Efr602/bc7tU5fu66RftzE2nYRVxAICSWZPAFE0lsbbw1qqdhUgD1tqY5GvQmHtrZ3dY2/C1t/A1+llmZ1LeeJ6fm1WSb6HV5HkR6pXRcl05yRgdwp/8jlNQPPgdp6B48DtOQfHgd5yCMlHBTyCQbFTEmpnmOUDqVTs0LXHRQ0k5ppAtKSkzYY2Xxeq2yRps4qYsRVZkAoBI7DH0STJKgAs1tTLfrtTsNnbeyvuePXXStL1y7DDpCbx5tmzaometMJYSAQ4AekS03HmQl69iImvW5+cmKdtnVBQQ/Fi1qiSy16Hb4/uKSSm0mGUFBdDpvWPapnbaslwAcO1P2fZ+m9vC31Z7zpPIXhsAyHrjC3xr8Se/4xQUD37HKSge/I5TUDz4HaegePA7TkGZbLmurARZHk31d/p1rlY26lZRntnLFc+4bpVbptoCQI8kt4hiPoYss+2l2M4MhCyVLHFHKJkHexsOqepZ3WY8Lt/Ct3vzninTduRZnun3+CsnbCPJN1Gd5dfhhp/ebdrqV/NkE1qx1tZyKXB9YzuINJDZWMS25zEpmxaY4WFXMon5uHK1tl9JeOKPuV3W9nvdrXxmoNM5bdqOt6yFHQC67dEbR0mm4xD+5HecguLB7zgFxYPfcQrKRsp1/aaIHBORw8N/n730w3Uc52KxkXJdAPBVVf29sfemEdAfzUx6/DUukLQ6VuC4MefZe7fvJRZS5ZlRE1KaK8sCa+HLNsOrkOywacptmqzcVyB1AM3CmpPcAQCAhFhu53m9+ahms8l+ZGEn7XvbvaQcWscKYx0idAFAs2qFKpnm1yGLrVWb6HKDbZBnVEwsuwAQkeubp6QUWsgeTMRbJhID3Hacsey/AIjTG9v2zNG+19xky4MtneIi7ZnTiyO/5zp+bYxxEngeB3B8+POKiLxbrstxnC3MRsp1AcCXReQ5EXnYq/Q6ztZiI+W6/hDAdQAOYvDJ4PcDr3uvXFcaWLXlOM7kWXe5LlU9qaqZDlwFfwTgLvba88t1lUh5a8dxNodx1H5aruvdOn1Dfg7A8xd/eI7jXCo2Uq7riyJyEIPqvG8C+KULbUggKK2RPTvLXNE+dtQqx0tneTKPOz5p9ceFq62tFQB6FVs7LiGJQwCg37VjS8inFw3Ye3Oi4IcSQzDbcAhWLrCf869U9YY9tmb7GO3bqdhzHtVIQhKWMQNAK7czNAGXNcrkcLOAUp337TlLlW84FXseUtjZnFIWsB2TaxmaGYhiknAmkMmZ1XiUgK18bsHW6ivVbeIQAFhqj9Y8zAKWcMZGynV9d+y9OI7zocMdfo5TUDz4HaegePA7TkGZbPZeESTJqP1y6RwvWVSCtT42bSJaAMBT/+tN03bznVfQvns/MmvacuVimcC256zcV8TfQ1m1rdB6/l5qbaFZINNvqcQuGxelesRuKiRXAgD0xVpxux07hlJgfXudrMfvdPk69D7R27KMC35CbtNQKbOcrGdnpb0qAS+xEkE2YworAOb6zXuB0m2ZtaAvkrJcAPDiM2+YtudfOEr7qqx/+tyf/I5TUDz4HaegePA7TkHx4HecguLB7zgFZaJqf5ZnaK6OJu8IZr5NrHKcZ1zZXD5pVeIfPWVtvABw7pSVaPddN0P7bttnk3lENauIR8Q+CgBZn7RnXClntuGI1SAEkKZMgefnpp/a8cZ0tgDodcl2E1sDkNUrBIB2187c1Os2ay0AdDOrdIvwZ1FFSfbdwHOrS2ZjhFiBo0CiFJaXpVS2dlsA6HWJ7bjFaya+/YY9N4efsKo+ALz1qk3Mkjb5dmvJqI19Sc7Qfgx/8jtOQfHgd5yC4sHvOAXFg99xCsom2HtHhanAsmp0OlYQqlatADfYiBWV3n7dlrQCgOPH7LroI69zq+jVB6zFeOFKO4Yr9vL0heUasYoyERAAiC01irjdtUTEqnJAxGu2bKZdDVhbk6oVlUj1K+SBbMdMtAzZe0Gy7IZKTfVzu784YKnOU9ueRFZkjTL+eu3aG7K1ykXL40etqPzS4ddo37desSJeb4Vvdza50rT16zxQ2itr4mT8al3+5HecouLB7zgFxYPfcQrKOAk8qyLyPRH5wbBc128N2/eLyJMi8qqIfENEuHvFcZwPJeMIfl0A96pqc5jC+29E5K8A/AsMynV9XUT+PYAvYZDLP0iWKZaXRwWKUoW/Z6SZFaWaq3z9M10HHhCEJLOHvHiciynvnHjbvj6xjrmrr9tFX3/jLVa42XUlTyxablhRS2Mu+MWJPTfdpi3LBQDVqj2/7T4voRWJPQ9lUmcqJWXIACAmwloacHAmZB16FjjePLL7U1b/CkBOttvvWZF2ZYmLlqtn7Ri+//RLtO9br1vx+OgbPNHmdNWWmpOMn5tWZ9G0RTl3cJqyZcQNGeKCT34d8K43MRn+UwD3AvjWsP0RAJ8fe6+O42w64xbtiIdpu08BeBTAawAWVd/LE3wUXr/PcbYUYwX/sDLPQQD7MKjMc9O4Ozi/XFdOFqQ4jrM5fCC1X1UXATwO4OMA5kTe++K1DwCtBHF+ua6o5OW6HOfDwjhq/04RmRv+XAPwGQAvYfAm8PPDbvcD+PalGqTjOBefcdT+3QAeEZEYgzeLb6rqX4rIiwC+LiL/GsCzGNTze19EAFlTvymKuXJcJtlZV5p8jX6LzAJMTdtsqQCgpJxRtxXIvluyKvFy09plz5FZAQA48opVfhf28XHt22/V4IUrpmnfxrT9BDU1s4P2zTtWUS6V+YxDItbem7XJV7WAhTQjMykRAmXTWlZV7weyFXfJ18U+S/8L4NypFdO2dMqucT/yMr9mR1+zJcu6TX5/zM/tsW0Nvva/LPZe6vT4jEOF2KRL5NoAQLUyej+9E8gOzRinXNdzAG4n7a8jUJnXcZwPP+7wc5yC4sHvOAXFg99xCsqEE3imWO6MimD1iAtgU1NWKEqXub23UrPvYVnK+85N2zX6bB06ACQVkrwytaesErAo9xetUPVOh7/fto7bvm/P8LXwEttkkHPzfAzzC/Z4Kw3eNydiKMupGUq6Sqp1od3mx8C20e1ze+/JE6dM2+JZXubtrSPH7bjE3mOsBBgAVGTBtM1Oc+E17VjRMQ7kCchI4ook4vddRCzKFZJIFQDqjVEhMVQ6ju5n7J6O41xWePA7TkHx4HecguLB7zgFxYPfcQrKRNV+CIB4VOXVQIba5qrNvqsslSyAqZott7WyzNXgc2dtooT5+Z20Lyt1NTdt1eAQFTJbEMqymxKrZ/MUP95c7cxA9xxP4nD0xydM28wct9wut6x9uly3Ej47LwDQ79tSaC2SPRgAqlWbuTYOqN+vv/amaWOKOABoZo8tJvvSQNKL5a69H4U7dpH3iXU6kNAqTux1bzT4LEKf3AsSGG+/P3ovaKiWGsGf/I5TUDz4HaegePA7TkHx4HecgjJZwU8BXWNzjIWvP15ZsuuyA9WckJetyDE7NUv7psRCGioDVq5YoSgnNk1WWgwAstQOuAcu4jGhxmRmfW/DpC58mwtCeW7f31vg57xatcLnKrkOnV6grBYRwKKAfTtXe2zdPl/PX4ZV3Oo1rsIJ3a695kyMBYASSVbQXuXjqib2vlm7vv5d1gpzAKDkOgJAr2PHWwoIxea2GV/v8ye/4xQVD37HKSge/I5TUDy1fsvzAAAG80lEQVT4HaegbKRW39dE5A0ROTz8d/DSD9dxnIvFRmr1AcC/VNVvvc9rR1AF8nRU4awkXB2tztv2VpNbdvsdq6SW61zN3bNnt2mbCtgs2y2r4i937BjiQMZUpuCHVNtez1pjU1aDEHzGQeJQnVTbt9XiMw5Rz57HDFaRFuXnttu256vT4TUEt8/ZJCOrTXsOAKBKsg0vneXbFZJ9pBRbKzDLpgsAkdprWQo8I2sVO+NQI1ZiAMgzO17NudrPEnKEknSIrNnG+KX6xsreqwBYrT7HcbYw66rVp6pPDv/0OyLynIh8VYQnFj+/XJcGnmSO40yeddXqE5FbAPwrDGr23QlgO4BfC7z2vXJd8gEKCjiOc2lZb62++1T1+LB8dxfAf4AX8HCcLcUFv/OLyE4AfVVdPK9W3++KyG5VPS4DxeHzAJ4fY1sox6PfDhbf4SW4KiQVbJpyqWFuxpa6mpnm9t6d262FtbnK15wzwa5MhLUM/OsMe70E3m/ZGm4o3269bsXQbo9bjHOxdtV+yoU1Ix4BWFo5Z9pqATH17Nmzpm12dnybdaSBsmnEjpz1+Lkps1JXRGQtExEQABYWrjBtrSY/t5HY7WaBr7ZCjiG09p6Nl12bwR8Cnvcx2Eitvv85fGMQAIcB/LN1j8JxnImzkVp9916SETmOMxHc4ec4BcWD33EKige/4xSUySbzgAD5eHP9KUkMUSlzKzBLmhFS1ZeWbFbgUIZZIWous1lmOVd454iFNUS5YtXnCFyRZsr+csuq8gAgJWIVjbly3F61FtQst7MQi4v8fNVq1trKZiYAoEcUdHYdAUBIUpPdC3tpX3YpspzM2iTchpvEdiajFIeSl1g7dJpy63S5Mv7MQJqRxB8kyQgAlMshW/eF8Se/4xQUD37HKSge/I5TUDz4HaegTDx7L9asRQ9lzq0SIWN2hgtoS4u2BBezhAJAr2sFGWbTBIAstyJLTtokIKAxOt02bWdCIjsHALB0+h3TlikvocXsrktL3FKtxELKbKXzC/P09ULWpy8t8hwMwkpdEbENAMolIiQGxN84IueMZIgOCWWLZ+25CeVVUGLrDuVrqDfsMYTuBRW73ZA4qLJWHPRyXY7jXAAPfscpKB78jlNQPPgdp6B48DtOQZmo2h9FYiygIRWTJeOYnuZZdjOiHDPrJcDVa5Y5FwByloyDvD40Y7FIZiGYXTa0XQ30bfesStxNueV2lSQJiRJ+2Rt1q0i3Vu2+gueWqP2hc5Pm9pxXyrxvnVhx2y1+zRp1q+L3yfWNAnUQIzIzsG3bDO272rJ1DJk1FwDaHXt9Qvd+FBPFnmQlBoBef9QmnYcKWrL9jN3TcZzLCg9+xykoHvyOU1A8+B2noEgog+gl2ZnIaQBHhr/uAHBmYjufHH5cW4/L6diuVlWbopow0eAf2bHI06p6aFN2fgnx49p6XM7H9n74x37HKSge/I5TUDYz+B/axH1fSvy4th6X87EF2bTv/I7jbC7+sd9xCsrEg19E7hORl0XkVRF5cNL7v5iIyMMickpEnj+vbbuIPCoirwz/37aZY1wPInKliDwuIi+KyAsi8svD9i19bCJSFZHvicgPhsf1W8P2/SLy5PCe/IaIrD8f9hZiosE/LPb57wD8AwAHAHxRRA5McgwXma8BuG9N24MAHlPVGwA8Nvx9q5EC+FVVPQDgbgD/fHidtvqxdQHcq6q3ATgI4D4RuRvA7wL4qqpeD+AcgC9t4hgnxqSf/HcBeFVVX1fVHoCvA/jchMdw0VDVvwawti715wA8Mvz5EQzKl28pVPW4qj4z/HkFwEsA9mKLH5sOeDepYDL8pwDuBfCtYfuWO671Mung3wvgrfN+Pzpsu5zYparHhz+fALBrMwezUUTkGgyqND+Jy+DYRCQWkcMATgF4FMBrABZV9d21z5fjPUlxwe8SooOplC07nSIiUwD+DMCvqOpInbOtemyqmqnqQQD7MPgketMmD2nTmHTwHwNw5Xm/7xu2XU6cFJHdADD8/9Qmj2ddiEiCQeD/iar++bD5sjg2AFDVRQCPA/g4gDn5/4UZL8d7kjLp4H8KwA1DdbUM4BcAfGfCY7jUfAfA/cOf7wfw7U0cy7qQQVqhPwbwkqr+wXl/2tLHJiI7RWRu+HMNwGcw0DMeB/Dzw25b7rjWy8RNPiLyWQD/BkAM4GFV/Z2JDuAiIiJ/CuBTGKwKOwngNwD8ZwDfBHAVBisYv6Cqa0XBDzUicg+A/wPgh8B75WF/HYPv/Vv22ETkVgwEvRiDB983VfW3ReRaDMTn7QCeBfBPVANVUC4j3OHnOAXFBT/HKSge/I5TUDz4HaegePA7TkHx4HecguLB7zgFxYPfcQqKB7/jFJT/B4DOpvIqcPp/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread(\"../cnn_training_data/0UmapByoNpPNzV3E.jpg\")\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 71  84 110]\n",
      "  [ 52  66  88]\n",
      "  [ 51  69  86]\n",
      "  ...\n",
      "  [ 77  98 113]\n",
      "  [ 84 103 118]\n",
      "  [ 54  73  88]]\n",
      "\n",
      " [[ 71  85 108]\n",
      "  [ 67  81 103]\n",
      "  [ 60  79  94]\n",
      "  ...\n",
      "  [ 74  95 110]\n",
      "  [ 87 106 121]\n",
      "  [ 77  96 111]]\n",
      "\n",
      " [[ 71  85 107]\n",
      "  [ 70  85 104]\n",
      "  [ 73  92 107]\n",
      "  ...\n",
      "  [ 67  87 104]\n",
      "  [ 75  96 111]\n",
      "  [ 90 111 126]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 43  53  70]\n",
      "  [ 59  72  88]\n",
      "  [ 61  77  93]\n",
      "  ...\n",
      "  [ 88 112 130]\n",
      "  [ 98 121 137]\n",
      "  [ 97 120 136]]\n",
      "\n",
      " [[ 48  59  73]\n",
      "  [ 60  73  87]\n",
      "  [ 50  66  82]\n",
      "  ...\n",
      "  [ 66  88 106]\n",
      "  [ 81 104 120]\n",
      "  [ 89 112 128]]\n",
      "\n",
      " [[ 68  80  92]\n",
      "  [ 66  79  93]\n",
      "  [ 38  57  72]\n",
      "  ...\n",
      "  [ 54  76  94]\n",
      "  [ 53  76  92]\n",
      "  [ 68  91 107]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(40, 40, 3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread(\"../cnn_training_data/1khX3CHvrgJqnIvV.jpg\")\n",
    "\"\"\"gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "\n",
    "# noise removal\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
    "\n",
    "# sure background area\n",
    "sure_bg = cv2.dilate(opening,kernel,iterations=3)\n",
    "\n",
    "# Finding sure foreground area\n",
    "dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
    "ret, sure_fg = cv2.threshold(dist_transform,0.7*dist_transform.max(),255,0)\n",
    "\n",
    "# Finding unknown region\n",
    "sure_fg = np.uint8(sure_fg)\n",
    "unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "\n",
    "# Marker labelling\n",
    "ret, markers = cv2.connectedComponents(sure_fg)\n",
    "\n",
    "# Add one to all labels so that sure background is not 0, but 1\n",
    "markers = markers+1\n",
    "\n",
    "# Now, mark the region of unknown with zero\n",
    "markers[unknown==255] = 0\n",
    "\n",
    "markers = cv2.watershed(img,markers)\n",
    "img[markers == -1] = [255,0,0]\n",
    "plt.imshow(img)\"\"\"\n",
    "print(img)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 13s 1us/step\n",
      "11501568/11490434 [==============================] - 13s 1us/step\n",
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "(train_x, train_y) , (test_x, test_y) = mnist.load_data()\n",
    "#train_x = train_x.astype('float32') / 255\n",
    "#test_x = test_x.astype('float32') / 255\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)\n",
    "\n",
    "train_x = train_x.reshape(60000,784)\n",
    "test_x = test_x.reshape(10000,784)\n",
    "\n",
    "train_y = keras.utils.to_categorical(train_y,10)\n",
    "test_y = keras.utils.to_categorical(test_y,10)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=128,activation=\"relu\",input_shape=(784,)))\n",
    "model.add(Dense(units=128,activation=\"relu\"))\n",
    "model.add(Dense(units=128,activation=\"relu\"))\n",
    "model.add(Dense(units=10,activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=SGD(0.001),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "#model.fit(train_x,train_y,batch_size=32,epochs=10,verbose=1)\n",
    "\n",
    "#accuracy = model.evaluate(x=test_x,y=test_y,batch_size=32)\n",
    "\n",
    "#print(\"Accuracy: \",accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
